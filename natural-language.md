# Natural language

## Introduction

TODO


## Tokenization

TODO


## word2vec

TODO


## seq2seq

-   RNNs
-   LSTMs
-   Watershed moment in NLP with deep learning


## Transformer

TODO


## BERT

TODO


## T5

-   Raffel, C. et al. (2019). [Exploring the limits of transfer learning with a unified text-to-text transformer](https://arxiv.org/abs/1910.10683).


## Conclusion

![Evolutionary tree of LLMs (source: [2304.13712](https://arxiv.org/abs/2304.13712)).](img/evolutionary-tree-of-LLMs.png)

-   Yang, J. et al. (2023). [Harnessing the power of LLMs in practice: A survey on ChatGPT and beyond](https://arxiv.org/abs/2304.13712).
-   Raschka, S. (2023). [Understanding large language models](https://magazine.sebastianraschka.com/p/understanding-large-language-models).

